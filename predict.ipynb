{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f82b09d-d1e8-42aa-a484-a008f3e59735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huynhcongbang/ai_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import statistics as stats\n",
    "from collections import Counter\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b44b3de-060b-4290-b02c-bbf2ab234575",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PUNCT_RE = re.compile(r\"[^\\w\\s]\", re.UNICODE)\n",
    "STOPWORDS = set([\"the\", \"be\", \"to\", \"of\", \"and\", \"a\", \"in\", \"that\", \"have\", \"i\", \n",
    "                 \"it\", \"for\", \"not\", \"on\", \"with\", \"he\", \"as\", \"you\", \"do\", \"at\"])\n",
    "\n",
    "def count_syllables(word):\n",
    "    word = word.lower()\n",
    "    if len(word) <= 3: return 1\n",
    "    word = re.sub(r'(?:[^laeiouy]es|ed|[^laeiouy]e)$', '', word)\n",
    "    word = re.sub(r'^y', '', word)\n",
    "    return max(1, len(re.findall(r'[aeiouy]{1,2}', word)))\n",
    "\n",
    "def shannon_entropy(text):\n",
    "    if not text: return 0\n",
    "    counts = Counter(text)\n",
    "    total = len(text)\n",
    "    return -sum((cnt / total) * math.log2(cnt / total) for cnt in counts.values())\n",
    "\n",
    "def extract_features_pro(text):\n",
    "    words = text.split()\n",
    "    sentences = [s for s in re.split(r\"[.!?]\", text) if s.strip()]\n",
    "    if not sentences: sentences = [text]\n",
    "    avg_sent_len = len(words) / max(1, len(sentences))\n",
    "    sent_lens = [len(s.split()) for s in sentences]\n",
    "    burstiness = stats.pstdev(sent_lens) / avg_sent_len if avg_sent_len > 0 else 0\n",
    "    num_syllables = sum(count_syllables(w) for w in words)\n",
    "    flesch_score = 206.835 - 1.015 * avg_sent_len - 84.6 * (num_syllables / max(1, len(words)))\n",
    "    stop_count = sum(1 for w in words if w.lower() in STOPWORDS)\n",
    "    \n",
    "    return {\n",
    "        \"len_words\": len(words),\n",
    "        \"ttr\": len(set(words)) / max(1, len(words)),\n",
    "        \"punct_ratio\": len(PUNCT_RE.findall(text)) / max(1, len(text)),\n",
    "        \"avg_sent_len\": avg_sent_len,\n",
    "        \"burstiness\": burstiness,\n",
    "        \"entropy\": shannon_entropy(text),\n",
    "        \"flesch_score\": flesch_score,\n",
    "        \"stopword_ratio\": stop_count / max(1, len(words))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "423dcedc-daf7-4410-8415-d0c71ac8d881",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPLScorer:\n",
    "    def __init__(self, model_name=\"distilgpt2\"):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name).to(self.device)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def perplexity(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            loss = self.model(**inputs, labels=inputs[\"input_ids\"]).loss\n",
    "        return float(torch.exp(loss))\n",
    "\n",
    "def load_model(path=\"aidetect_model_pro.joblib\"):\n",
    "    data = joblib.load(path)\n",
    "    print(\"âœ… Model Pro loaded successfully.\")\n",
    "    return data[\"pipe\"], data[\"feat_names\"], PPLScorer()\n",
    "\n",
    "def predict_text(text, pipe, feat_names, scorer):\n",
    "    f = extract_features_pro(text)\n",
    "    f[\"ppl\"] = scorer.perplexity(text)\n",
    "    # Äáº£m báº£o thá»© tá»± feature Ä‘Ãºng nhÆ° lÃºc train\n",
    "    vector = np.array([f[name] for name in feat_names]).reshape(1, -1)\n",
    "    return pipe.predict_proba(vector)[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0084be-404f-44dd-a4ae-6b8f1227ea72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model Pro loaded successfully.\n",
      "\n",
      "=== AI TEXT DETECTOR  ===\n",
      "Nháº­p Ä‘oáº¡n vÄƒn tiáº¿ng Anh Ä‘á»ƒ kiá»ƒm tra. GÃµ 'exit' Ä‘á»ƒ thoÃ¡t.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  In this study, we propose a planetary gear degradation state recognition method based on features with multiple perspectives and LLTSA. Firstly, feature extraction is used to collect vibration data from the gears. Then, time-domain analysis is conducted to characterize the degradation of the gears. Data mining is performed to discover the relevant features of the gear vibrations, and dimensionality reduction is used to select the most significant features. Finally, LLTSA is used to build a recognition model based on the extracted features. The proposed method effectively captures the degradation characteristics of planetary gears and provides an accurate recognition of the gear's state. This research provides a valuable contribution to the field of gear degradation recognition, and further research can be conducted to improve the accuracy and efficiency of the proposed method.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 49.3% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  NGÆ¯á»œI viáº¿t ðŸ§‘\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  This paper proposes an active learning method for gearbox fault diagnosis, which is based on the concepts of uncertainty and complexity. The approach is centered on the use of supervised learning algorithms to train models with radio frequency data that can help to understand and identify different fault states. One of the key features of the method is the way it selectively chooses samples to train the models, based on their level of uncertainty and complexity. This is achieved through the application of a complexity theory-inspired approach that seeks to balance the trade-off between model accuracy and computational efficiency. The experimental results demonstrate that the proposed method outperforms existing approaches in terms of both diagnostic accuracy and computational efficiency. In summary, this paper provides a novel approach to fault diagnosis that combines the strengths of supervised learning, uncertainty, and complexity theory to improve the performance of diagnosis systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘] 99.8% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  AI viáº¿t ðŸ¤–\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  Often, images captured by digital camera in outdoor vision system may be significantly distorted by bad weather conditions. Such visual distortions may negatively affect the performance of the system. One such bad weather condition is rain, which randomly makes intensity fluctuations in the images. This paper proposes a new low rank recovery based algorithm to remove the rain streaks from single image taken in rainy weather. This method makes the use of weighted nuclear norm (WNN) and total variation (TV) regularization for efficient rain removal. WNN assigns different weights to different singular values based on the details each singular value holds. TV regularization is used to discriminate most of natural image content from sparse rain streaks by preserving piecewise smoothness of images. Simulation result shows that the rain streaks are more efficaciously eliminated by our method.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 1.8% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  NGÆ¯á»œI viáº¿t ðŸ§‘\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  This paper discusses the key technologies and applications of AC/DC hybrid distributed renewable energy systems. The study focuses on renewable energy sources, including solar, wind, and hydroelectric power, and their integration into power distribution systems. The simulation of hybrid power systems plays a vital role in the development and optimization of power grids, and this research highlights the importance of power electronics in controlling the flow of energy between the AC and DC grids. Furthermore, the paper investigates the challenges and opportunities faced in incorporating distributed renewable energy sources in distribution networks, and outlines the benefits and drawbacks of hybrid power systems. This literature review serves as a useful reference for researchers and engineers interested in implementing renewable energy sources in existing power grids.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘] 99.6% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  AI viáº¿t ðŸ¤–\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  n this paper, a fast amplitude determination method for switching overvoltage in black-start plans based on gas turbine distributed energy supply system is proposed. The method utilizes support vector machines and analytical models for training and prediction, and takes into account the impact of power transmission lines and switches on the accuracy of voltage amplitude determination. In addition, artificial neural networks are utilized to build predictive models for a more accurate and efficient determination of switching overvoltage amplitudes. The proposed method shows significant improvement in speed and accuracy compared with traditional methods, and provides a promising solution for the safe and reliable operation of black-start plans with gas turbine distributed energy supply system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 57.9% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  AI viáº¿t ðŸ¤–\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  Lately, the problem of code-switching has gained a lot of attention and has emerged as an active area of research. In bilingual communities, the speakers commonly embed the words and phrases of a non-native language into the syntax of a native language in their day-to-day communications. The code-switching is a global phenomenon among multilingual communities, still very limited acoustic and linguistic resources are available as yet. For developing effective speech-based applications, the ability of the existing language technologies to deal with the code-switched data cannot be over emphasized. The code-switching is broadly classified into two modes: inter-sentential and intra-sentential code-switching. In this work, we have studied the intrasentential problem in the context of code-switching language modeling task. The salient contributions of this paper includes: (i) the creation of Hindi-English code-switching text corpus by crawling a few blogging sites educating about the usage of the Internet, and (ii) the exploration of the parts-of-speech features towards more effective modeling of Hindi-English code-switched data by the monolingual language models trained on native (Hindi) language data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.6% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  NGÆ¯á»œI viáº¿t ðŸ§‘\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  In recent years, the natural language processing (NLP) community has witnessed a paradigm shift with the introduction of Large Language Models (LLMs) [1],[2]. The formidable capabilities of LLMs have raised concerns about distinguishing between their generated texts and human-written content. These concerns stem from two main issues\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 23.5% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  NGÆ¯á»œI viáº¿t ðŸ§‘\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  High-quality datasets have a key role in advancing research in LLM-generated text detection. These datasets allow researchers to quickly develop and calibrate effective detectors and establish standardized metrics to evaluate the effectiveness of their methods. In this section, we introduce popular datasets used for LLM-generated text detection, widely contributed by recent studies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 56.1% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  AI viáº¿t ðŸ¤–\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  Watermarking techniques is an indispensable part of detecting images generated by AI, contributing to protecting intellectual property rights and ownership in visual arts. With the emergence of LLMs, watermarking techniques has been extended to be applicable to identifying text generated by these models. Methods applying watermarking techniques include tatistical Methods [6], Secret Key-Based Watermarking Technology [7], etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 1.3% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  NGÆ¯á»œI viáº¿t ðŸ§‘\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  Artificial Intelligence has revolutionized the way we interact with digital systems. In recent years, deep learning models have achieved significant milestones in natural language processing tasks. These models are capable of understanding and generating human-like text with remarkable accuracy. Furthermore, the integration of AI into various industries, such as healthcare and finance, is expected to improve efficiency and reduce operational costs. Therefore, it is crucial for researchers to continue exploring the potential applications of these technologies while addressing ethical concerns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 91.8% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  AI viáº¿t ðŸ¤–\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  While recent strides in Large Language Models (LLMs) are undeniable, the 'black box' problem persists. We argue that interpretability isn't just a feature; it's a necessity. Why? Because without understanding the underlying decision boundariesâ€”specifically in high-stakes domains like healthcareâ€”deployment remains risky. Our experiment utilized a novel perturbation method, revealing that even state-of-the-art transformers fail to maintain consistency when subjected to minor adversarial noise during the inference phase\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 1.2% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  NGÆ¯á»œI viáº¿t ðŸ§‘\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  AI-generated text detection refers to the use of AI technology to identify and detect text content generated by an AI system that may contain false information, misleading information, or content that violates regulations [1]. With the continuous development and popularisation of deep learningtechnology, AI-generated text detection plays an increasingly important role in the fields of networksecurity, public opinion monitoring, news media, etc. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 41.6% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  NGÆ¯á»œI viáº¿t ðŸ§‘\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  Text preprocessing is a very important step in natural language processing that helps to cleanandprepare text data for subsequent analysis or modelling. In this paper, the text is sequentially, convertedto lowercase, word splitting, removal of stop words, stemming extraction, removal of numbers andremoval of redundant spaces and other steps [7]. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 1.9% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  NGÆ¯á»œI viáº¿t ðŸ§‘\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  In this century, the invention of technology changes peopleâ€™s life. People could easily participate in some activities, and they believe that technology have some negative impacts for social relationship. However, other people think that technology aids them to communicate more effectively than previous years.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 35.9% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  NGÆ¯á»œI viáº¿t ðŸ§‘\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  Some people give opinions that technology has a tendency to reduce people to face-to-face because some sophisticated tools encourage people do not need to make appointments to meet in some places. Also, people seem busy with their smartphone. It could influences relationship between societies and environment. Based on some researches, people tend to pay particular attention toward their mobile gadgets than real friends. That phenomenon is called by blind relationship. For instance, some students are more familiar with several social media websites such as Facebook and Twitter than their classmates. It is true that development of technology gives strong effect for some people who live in this modern era. Viáº¿t cho Tuong Zi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.6% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  NGÆ¯á»œI viáº¿t ðŸ§‘\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  Artificial Intelligence has revolutionized the way we interact with digital systems. In recent years, deep learning models have achieved significant milestones in natural language processing tasks. These models are capable of understanding and generating human-like text with remarkable accuracy. Furthermore, the integration of AI into various industries, such as healthcare and finance, is expected to improve efficiency and reduce operational costs. Therefore, it is crucial for researchers to continue exploring the potential applications of these technologies while addressing ethical concerns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 91.8% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  AI viáº¿t ðŸ¤–\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  With the rapid development and wide application of deep learning technology, AI-generatedtext detection plays an increasingly important role in today's network security, public opinion monitoring, news media and other fields. In this study, an innovative AI-generated text detection model is constructed based on the BERT algorithm, which provides a novel solution for this field. In thedatapreprocessing stage, a series of steps were taken, including operations such as converting text tolowercase, performing word splitting, removing stop words, stemming extraction, and eliminatingnumbers and redundant spaces. By dividing the dataset into training and test sets in the ratio of 60%and 40%, we observe that the accuracy rate grows from the initial 94.78%to 99.72%duringthetraining process, which indicates that the BERT model is able to detect the AI-generated text withhighaccuracy; at the same time, the loss value decreases from the initial 0.261 to 0.021 and tends tobestable, and the model's prediction results are gradually close to the real classification results. Further analysis of the results of the training and test sets shows that the average loss of the trainingset is 0.0565, while the average loss of the test set is 0.0917, which shows that the test set has a slight upward trend relative to the training set. In terms of accuracy, the average accuracy of the trainingset reaches 98.1%, while the average accuracy of the test set is 97.71%, with only a 0.39%differencebetween the two. This indicates that the model has good generalisation ability and can achieve highaccuracy on unknown data. In conclusion, the AI-generated text detection model based on BERT algorithmproposedinthisstudy performs well after sufficient training. By effectively processing and reasonably dividingthedata and combining with excellent deep learning algorithms, it has achieved remarkable results inthefield of AI-generated text detection. The model not only exhibits high accuracy and lowloss valueonthe training set, but also shows relatively stable and excellent performance on the test set. Thisresearch result is not only of great significance for improving the level of AI-generated text detectiontechnology, but also provides a useful reference for further research and practice in related fields. Inthe future, we can further expand the data scale, optimise the model architecture and explore moreeffective feature engineering methods, in order to further improve the effectiveness and reliabilityof AI-generated text detection technology in various application scenarios. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.1% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  NGÆ¯á»œI viáº¿t ðŸ§‘\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  When we look up at the night sky, one object often outshines all the stars. It is Venus, known as the \"Morning Star\" or the \"Evening Star.\" Named after the Roman goddess of love and beauty, this planet has captivated human imagination for millennia. However, modern science has revealed a startling contrast: while Venus looks beautiful from afar, up close it is a hellish world. It is often called Earthâ€™s \"evil twin\"â€”a planet that started with similar ingredients to our own but evolved into a toxic inferno.  The Sister Planet In terms of size and structure, Venus is remarkably similar to Earth.  Size: It has a diameter of about 12,104 kilometers, only slightly smaller than Earth.  Composition: It is a rocky planet with an iron core and a silicate mantle.  Gravity: Its gravity is about 90% of Earth's, meaning you would feel almost the same weight standing there.  Because of these similarities, astronomers believe that billions of years ago, Venus might have been a habitable world with liquid water oceans. However, a catastrophic chain of events changed its destiny forever.  The Runaway Greenhouse Effect The defining characteristic of Venus is its terrifying atmosphere. It is the hottest planet in our solar system, even though Mercury is closer to the Sun. This is due to a phenomenon known as the runaway greenhouse effect.  The atmosphere is extremely dense, consisting of 96% carbon dioxide. This thick blanket of gas traps heat from the Sun and prevents it from escaping back into space. Consequently, the average surface temperature is a scorching 475Â°C (900Â°F)â€”hot enough to melt lead.  Furthermore, the atmospheric pressure on the surface is crushing. Standing on Venus would feel like being 900 meters (3,000 feet) underwater on Earth. To make matters worse, the planet is shrouded in thick clouds of sulfuric acid, which rain down virga (rain that evaporates before hitting the ground).  A World in Retrograde Venus behaves differently from most other planets in its motion.  Retrograde Rotation: Venus spins in the opposite direction to Earth. On Venus, the Sun rises in the west and sets in the east.  The Long Day: It rotates incredibly slowly. One day on Venus (one full rotation) takes 243 Earth days, while one year (orbit around the Sun) takes only 225 Earth days. This means a day on Venus is actually longer than its year!  The Surface and Exploration Because of the thick clouds, we cannot see the surface through simple telescopes. We rely on radar mapping and daring space probes to understand the landscape.  The surface of Venus is dominated by volcanic activity. It is covered in vast plains of solidified lava, thousands of volcanoes, and large impact craters. The highest mountain, Maxwell Montes, stands taller than Mount Everest.  Exploring this surface has been one of the hardest challenges in space history. Between the 1960s and 1980s, the Soviet Union sent a series of Venera probes to land on the planet. These represent the only times humans have successfully transmitted photos from the surface. However, the conditions are so hostile that the longest-surviving lander, Venera 13, lasted only 127 minutes before succumbing to the heat and pressure.  Conclusion: A Warning for Earth Venus remains a subject of intense study, not just for curiosity, but for survival. It serves as a cautionary tale for Earth. By studying the extreme greenhouse effect on Venus, scientists hope to better understand climate change on our own planet.  While it may not be the paradise of \"love and beauty\" that the ancients imagined, Venus is scientifically invaluable. It is a stunning, dangerous, and complex world that reminds us just how fragile and precious the habitable conditions of Earth truly are.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 4.2% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  NGÆ¯á»œI viáº¿t ðŸ§‘\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  Venus is often called Earth's \"evil twin\" because they share a similar size, yet Venus is a toxic inferno. It is the hottest planet in the solar system, with a crushing atmosphere of carbon dioxide that traps heat, raising temperatures to 475Â°C. Interestingly, Venus rotates in the opposite direction to most planets, meaning the Sun rises in the west. Despite its beautiful brightness in the night sky, its surface is a volcanic wasteland where no life can survive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 22.4% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  NGÆ¯á»œI viáº¿t ðŸ§‘\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  Science and technology are the driving forces of human progress, transforming how we live, work, and communicate. While science helps us understand the laws of nature through research, technology applies that knowledge to create practical tools and solutions. Today, breakthroughs in fields like Artificial Intelligence (AI) and renewable energy are solving global challenges and shaping a sustainable future. Ultimately, the partnership between scientific discovery and technological innovation is essential for the advancement of our society.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘] 97.7% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  AI viáº¿t ðŸ¤–\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  Itâ€™s hard to imagine what our lives would be like without science and technology. They aren't just subjects in a textbook; they shape everything we do, from the smartphones in our pockets to the medicine that keeps us healthy. Science gives us the \"why,\" and technology gives us the \"how\" to solve real-world problems. With exciting changes like AI and clean energy happening right now, we aren't just dreaming of a better futureâ€”we are actively building it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 34.0% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  NGÆ¯á»œI viáº¿t ðŸ§‘\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> Nháº­p vÄƒn báº£n:  The dataset is divided according to 60% and 40% and used as training set and test set respectively, thenumber of training rounds is set to 10, the graphic card used for the experiment is 3090, the GPUis32G, and the experiment is conducted using python 3.10. The changes in accuracy and loss duringthetraining process were recorded and the results are shown in Fig. 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Káº¾T QUáº¢: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.9% AI\n",
      "=> Kháº£ nÄƒng cao lÃ  NGÆ¯á»œI viáº¿t ðŸ§‘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe, feat_names, scorer = load_model()\n",
    "\n",
    "print(\"\\n=== AI TEXT DETECTOR  ===\")\n",
    "print(\"Nháº­p Ä‘oáº¡n vÄƒn tiáº¿ng Anh Ä‘á»ƒ kiá»ƒm tra. GÃµ 'exit' Ä‘á»ƒ thoÃ¡t.\\n\")\n",
    "\n",
    "while True:\n",
    "    text = input(\">> Nháº­p vÄƒn báº£n: \").strip()\n",
    "    if not text: continue\n",
    "    if text.lower() in [\"exit\", \"quit\"]: break\n",
    "    \n",
    "    try:\n",
    "        prob_ai = predict_text(text, pipe, feat_names, scorer)\n",
    "        \n",
    "        # Váº½ thanh tiáº¿n Ä‘á»™ cho Ä‘áº¹p\n",
    "        bar_len = 20\n",
    "        filled = int(prob_ai * bar_len)\n",
    "        bar = \"â–ˆ\" * filled + \"â–‘\" * (bar_len - filled)\n",
    "        \n",
    "        print(f\"\\nKáº¾T QUáº¢: [{bar}] {prob_ai*100:.1f}% AI\")\n",
    "        if prob_ai > 0.5:\n",
    "            print(\"=> Kháº£ nÄƒng cao lÃ  AI viáº¿t ðŸ¤–\\n\")\n",
    "        else:\n",
    "            print(\"=> Kháº£ nÄƒng cao lÃ  NGÆ¯á»œI viáº¿t ðŸ§‘\\n\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Lá»—i: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d879491-cee0-4200-8d3b-a048f155875b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai_env)",
   "language": "python",
   "name": "ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
