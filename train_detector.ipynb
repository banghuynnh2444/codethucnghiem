{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d438c1d2-1866-4633-ad46-dbb068ec9b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huynhcongbang/ai_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "import random\n",
    "import joblib\n",
    "import numpy as np\n",
    "import statistics as stats\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ed0fcf3-4637-49cf-bb03-ff612bdeeda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C·∫•u h√¨nh Regex v√† Stopwords\n",
    "PUNCT_RE = re.compile(r\"[^\\w\\s]\", re.UNICODE)\n",
    "STOPWORDS = set([\"the\", \"be\", \"to\", \"of\", \"and\", \"a\", \"in\", \"that\", \"have\", \"i\", \n",
    "                 \"it\", \"for\", \"not\", \"on\", \"with\", \"he\", \"as\", \"you\", \"do\", \"at\"])\n",
    "\n",
    "def count_syllables(word):\n",
    "    \"\"\"ƒê·∫øm √¢m ti·∫øt ƒë∆°n gi·∫£n ƒë·ªÉ t√≠nh ch·ªâ s·ªë Readability\"\"\"\n",
    "    word = word.lower()\n",
    "    if len(word) <= 3: return 1\n",
    "    word = re.sub(r'(?:[^laeiouy]es|ed|[^laeiouy]e)$', '', word)\n",
    "    word = re.sub(r'^y', '', word)\n",
    "    syllables = len(re.findall(r'[aeiouy]{1,2}', word))\n",
    "    return max(1, syllables)\n",
    "\n",
    "def shannon_entropy(text):\n",
    "    \"\"\"T√≠nh ƒë·ªô h·ªón lo·∫°n th√¥ng tin (Entropy) c·ªßa k√Ω t·ª±\"\"\"\n",
    "    if not text: return 0\n",
    "    counts = Counter(text)\n",
    "    total = len(text)\n",
    "    return -sum((cnt / total) * math.log2(cnt / total) for cnt in counts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9206c00-d360-43b1-88bf-9412ef5d4617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_pro(text):\n",
    "    words = text.split()\n",
    "    sentences = [s for s in re.split(r\"[.!?]\", text) if s.strip()]\n",
    "    if not sentences: sentences = [text]\n",
    "    \n",
    "    num_words = len(words)\n",
    "    num_sentences = len(sentences) # S·ª≠a l·ªói chia cho 0\n",
    "    avg_sent_len = num_words / max(1, num_sentences)\n",
    "    \n",
    "    # Burstiness (ƒê·ªô bi·∫øn thi√™n ƒë·ªô d√†i c√¢u)\n",
    "    sent_lens = [len(s.split()) for s in sentences]\n",
    "    burstiness = stats.pstdev(sent_lens) / avg_sent_len if avg_sent_len > 0 else 0\n",
    "    \n",
    "    # Readability (Flesch Reading Ease gi·∫£ l·∫≠p)\n",
    "    num_syllables = sum(count_syllables(w) for w in words)\n",
    "    flesch_score = 206.835 - 1.015 * avg_sent_len - 84.6 * (num_syllables / max(1, num_words))\n",
    "    \n",
    "    # Stopword Ratio (AI th∆∞·ªùng d√πng t·ª∑ l·ªá t·ª´ d·ª´ng r·∫•t chu·∫©n m·ª±c)\n",
    "    stop_count = sum(1 for w in words if w.lower() in STOPWORDS)\n",
    "    \n",
    "    return {\n",
    "        \"len_words\": num_words,\n",
    "        \"ttr\": len(set(words)) / max(1, num_words),\n",
    "        \"punct_ratio\": len(PUNCT_RE.findall(text)) / max(1, len(text)),\n",
    "        \"avg_sent_len\": avg_sent_len,\n",
    "        \"burstiness\": burstiness,\n",
    "        \"entropy\": shannon_entropy(text),        # M·ªõi\n",
    "        \"flesch_score\": flesch_score,            # M·ªõi\n",
    "        \"stopword_ratio\": stop_count / max(1, num_words) # M·ªõi\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "275b6d1c-3937-41d3-a6eb-238eb6920d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPLScorer:\n",
    "    def __init__(self, model_name=\"distilgpt2\"):\n",
    "        print(f\"Loading LM: {model_name}...\")\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name).to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def perplexity(self, text):\n",
    "        # C·∫Øt ng·∫Øn text xu·ªëng 512 tokens ƒë·ªÉ tr√°nh l·ªói tr√†n b·ªô nh·ªõ\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            loss = self.model(**inputs, labels=inputs[\"input_ids\"]).loss\n",
    "        return float(torch.exp(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00b7c03b-1ca9-4c4c-ab90-00c816f50f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15395 samples from human.txt\n",
      "Loaded 15527 samples from ai.txt\n",
      "üî• T·ªïng c·ªông: 30922 m·∫´u d·ªØ li·ªáu s·∫µn s√†ng.\n"
     ]
    }
   ],
   "source": [
    "def load_texts(human_file=\"human.txt\", ai_file=\"ai.txt\"):\n",
    "    texts, labels = [], []\n",
    "    for f_path, label in [(human_file, 0), (ai_file, 1)]:\n",
    "        try:\n",
    "            with open(f_path, encoding=\"utf-8\") as f:\n",
    "                content = f.read().split(\"\\n\\n\")\n",
    "                print(f\"Loaded {len(content)} samples from {f_path}\")\n",
    "                for t in content:\n",
    "                    if len(t.strip()) > 30:\n",
    "                        texts.append(t.strip())\n",
    "                        labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {f_path}: {e}\")\n",
    "    return texts, labels\n",
    "\n",
    "# Th·ª±c thi load data\n",
    "texts, labels = load_texts()\n",
    "\n",
    "# Shuffle d·ªØ li·ªáu\n",
    "combined = list(zip(texts, labels))\n",
    "random.shuffle(combined)\n",
    "texts, labels = zip(*combined)\n",
    "texts, labels = list(texts), list(labels)\n",
    "print(f\"üî• T·ªïng c·ªông: {len(texts)} m·∫´u d·ªØ li·ªáu s·∫µn s√†ng.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e987e48-3c47-40e5-89e5-3ef021b11747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LM: distilgpt2...\n",
      "‚è≥ ƒêang tr√≠ch xu·∫•t features (vui l√≤ng ƒë·ª£i)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/30922 [00:00<?, ?it/s]`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30922/30922 [1:51:55<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ tr√≠ch xu·∫•t xong ƒë·∫∑c tr∆∞ng!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scorer = PPLScorer()\n",
    "X_data = []\n",
    "feat_names = []\n",
    "\n",
    "print(\"‚è≥ ƒêang tr√≠ch xu·∫•t features (vui l√≤ng ƒë·ª£i)...\")\n",
    "for t in tqdm(texts):\n",
    "    f = extract_features_pro(t)\n",
    "    f[\"ppl\"] = scorer.perplexity(t)\n",
    "    X_data.append(list(f.values()))\n",
    "    if not feat_names: feat_names = list(f.keys())\n",
    "\n",
    "X = np.array(X_data)\n",
    "y = np.array(labels)\n",
    "print(\"‚úÖ ƒê√£ tr√≠ch xu·∫•t xong ƒë·∫∑c tr∆∞ng!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a241d026-b276-470b-844e-6d4d454be369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ ƒêang hu·∫•n luy·ªán Ensemble Model...\n",
      "üèÅ Hu·∫•n luy·ªán ho√†n t·∫•t!\n"
     ]
    }
   ],
   "source": [
    "# Chia t·∫≠p train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a 3 model con\n",
    "clf1 = LogisticRegression(random_state=1, max_iter=1000)\n",
    "clf2 = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "clf3 = SVC(probability=True, random_state=1)\n",
    "\n",
    "# K·∫øt h·ª£p b·∫±ng Soft Voting\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', clf1), ('rf', clf2), ('svm', clf3)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Pipeline v·ªõi PowerTransformer (t·ªët h∆°n StandardScaler cho d·ªØ li·ªáu b·ªã l·ªách)\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", PowerTransformer()), \n",
    "    (\"voting\", voting_clf)\n",
    "])\n",
    "\n",
    "print(\"üöÄ ƒêang hu·∫•n luy·ªán Ensemble Model...\")\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"üèÅ Hu·∫•n luy·ªán ho√†n t·∫•t!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f051a9dc-8667-46a0-8f7c-00fe08b245dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "üèÜ K·∫æT QU·∫¢ ƒê√ÅNH GI√Å (PRO VERSION)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9609    0.9581    0.9595      3079\n",
      "           1     0.9586    0.9614    0.9600      3106\n",
      "\n",
      "    accuracy                         0.9597      6185\n",
      "   macro avg     0.9597    0.9597    0.9597      6185\n",
      "weighted avg     0.9597    0.9597    0.9597      6185\n",
      "\n",
      "ROC-AUC Score: 0.9924\n",
      "Cross-Validation Accuracy (5-fold): 0.9597 (+/- 0.0041)\n",
      "\n",
      "üíæ ƒê√£ l∆∞u model v√†o: aidetect_model_pro.joblib\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"üèÜ K·∫æT QU·∫¢ ƒê√ÅNH GI√Å )\n",
    "print(\"=\"*40)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "\n",
    "# Cross Validation check\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy (5-fold): {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "\n",
    "# L∆∞u model\n",
    "joblib.dump({\"pipe\": pipe, \"feat_names\": feat_names}, \"aidetect_model_pro.joblib\")\n",
    "print(f\"\\nüíæ ƒê√£ l∆∞u model v√†o: aidetect_model_pro.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefb9dc6-01c0-4e5a-9952-d5e5aea19109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai_env)",
   "language": "python",
   "name": "ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
